{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bA05XuYXYBEr"
   },
   "source": [
    "# Introduction to Prompt Engineering with Large Language Models\n",
    "\n",
    "In this notebook, you'll learn how to interact with large language models (LLMs) using prompting.\n",
    "\n",
    "We will explore:\n",
    "\n",
    "- Basic prompts\n",
    "- Improving prompts with context\n",
    "- Few-shot examples\n",
    "- Using prompt templates\n",
    "\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/cbadenes/semantic-report-search/blob/main/data/analysis/40_prompting_basics.ipynb\" target=\"_parent\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IsxlWad5eaFA",
    "outputId": "74497cf0-7bf1-4d3d-d893-60afc4789e3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔑 Enter your Hugging Face token: ··········\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import getpass\n",
    "\n",
    "token = getpass.getpass(\"🔑 Enter your Hugging Face token: \")\n",
    "login(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258,
     "referenced_widgets": [
      "9d800eb31b4c41d0a736098e38e20582",
      "ae520486008342fb8df7e956b5c1096a",
      "c2d265f7157e482586e9b25734534d31",
      "0e0666aa6c51406facc081daab3e82cb",
      "ffda44cd76f84f14bdba73e76f88860f",
      "c9f3466ef69042f596d6bfa11a7d7ac4",
      "f1d56ae8948849098eef9b150f95da22",
      "cb6372cff2ff4977a10cf9ca4bcecedc",
      "5728363e89894037b2902cae7f965b56",
      "529eb95d5bfa48feac9249659fb46f0e",
      "2b3b3c22032c47ebba3b456e187bffd0",
      "5532b27638374538849d574b84f55b4e",
      "24383e8c2dc849fa8e800fd94080d6b5",
      "40f25e78dce04533b54caf9896787b27",
      "f187b05fe6814ea398c04f3159d8b865",
      "151c03e86a03470aa10601e9c451a478",
      "7899f419c55e499ca18eae17a79a4158",
      "9bb63a78198c4182b3556546311a5d29",
      "382a11046c284f0cb13006e0489c9b27",
      "126c3af5a3114ec78e414d576cf6933f",
      "30d6b043e2944a85be3e6ab350c37e0b",
      "7d3094d30b9f46c4b3505919bf81bebd",
      "d902a3f0a0f04b8694e91b3ca0cb6509",
      "9539d0a4fbfd42a8b9d8b5621c375226",
      "bdf9485875fd4886a523266929415d01",
      "caea11b3bf184921ae6a37d0449b47aa",
      "eec5e0bd5b054dcbb702f6ddf8a84250",
      "1a2740a3819143c7893f1136e7b417f9",
      "fdf05c88ca0844e4915f4c9b01322edd",
      "364d770812f2487687b0510f49ef4265",
      "323edc37c4d04511bd524551126fd899",
      "b2b3eaa843f84288b71ed69f48afee08",
      "9e803dc13c5b44aabc9098874ba56d1c",
      "94d6890f4f2142e0b9df938c804c398c",
      "a03e02fb5cd74b9a8d42e24f88e005a8",
      "db550bb685304a9a9f4259a3d6a63351",
      "d86b670747004d58b35a75700b545aa4",
      "48bdf586dd1645d7b9d971ab50a3019d",
      "d5981f424fc941b7820debc3929c53bc",
      "30c25d1fd27043ef8305b27139cc21ba",
      "8be881ea1bb54285a8b42440da9b5e36",
      "55a14d84fd72447b9686e426cf79220c",
      "3ea95feb628e4d258aac5442bd9a33b0",
      "2a3e520a309c463d93e7da7217475a87",
      "8ac3d7e5dc674fc08e31af6a96a90a7b",
      "2ba1e8c77f6a47f28772aff99af4451a",
      "00b530ae46974847b282e931b5eb6967",
      "0ca339a36cba42ce8426c03e6bac0952",
      "412b66b5e6a24d0fbd375b6ae659b6ad",
      "4256e24592664e73a3c76042b1c2fc0c",
      "e8fec05d261e4472a98d8a697cfde40a",
      "14ee06d8103a4cb8b5197505f1e189e7",
      "ab421bc7ab914aeaa6b66a88fefaf93d",
      "cb7c7803c9064c2ead7c605bd3b3d21e",
      "795a73f7d7084bbbb3a26a1572a41f5e",
      "c4aac3a3596941e9b7be257e018fcb54",
      "6885afa674cd46ea99f3ffa534f4d12c",
      "75756d45b9614b279d8f10398a876b88",
      "33726e14704a42d582d9d99d0747d68e",
      "fbef09d96e4f4999aac23c9330d5d9fa",
      "9f54b073be094cb5b8ebea03470a0882",
      "062f83103a8d4baf9c2688828fdfa744",
      "825c6092bb0247038961b081fa843722",
      "6d51db6623284b3ca2c35317480417cc",
      "91071e068e1545d5a888c850c56aa222",
      "9600a8eea51042ad81f4cad9b520b763",
      "dbbc3842cc1d4d1887127063badb6ddd",
      "520d6fd3bb66491393a853fc1a71c0e5",
      "632530dbedbe456c9da44e9aef306bc8",
      "59e6a60e014c4103adfe8885bc400d27",
      "c1d2eaf8b8f240f096661ad18f4e7445",
      "91ec078952d84a76bbba57a277236363",
      "027596ef3ee94592b6dbda37d4a176e9",
      "f2f5ccd63bcc46918613879d20a50dc2",
      "a8ef9fd46369478a81c72f5ca2e05b92",
      "bbff2e638c0e499aa4478dd83ea966ad",
      "3664daae469740a287b0927416141c77"
     ]
    },
    "id": "HDc15w0_YK3X",
    "outputId": "63f61dc0-039b-4548-c5e6-b4d270150b2a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d800eb31b4c41d0a736098e38e20582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5532b27638374538849d574b84f55b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d902a3f0a0f04b8694e91b3ca0cb6509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d6890f4f2142e0b9df938c804c398c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac3d7e5dc674fc08e31af6a96a90a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4aac3a3596941e9b7be257e018fcb54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbbc3842cc1d4d1887127063badb6ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers accelerate\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", token=token)\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GymAuVhYUQK"
   },
   "source": [
    "Basic Prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gODa1bYTYSB0",
    "outputId": "93ea4633-8eec-4b03-c11f-19e22cff0a90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are a helpful assistant.\n",
      "<|user|>\n",
      "Summarize the purpose of a report that analyzes the distribution flows in feeder markets.\n",
      "<|assistant|>\n",
      "The purpose of a report that analyzes the distribution flows in feeder markets is to provide insights into the distribution of goods and services within a specific geographic area, including the distribution of goods and services between different regions or markets. The report may also examine the factors that influence the distribution of goods and services, such as transportation, logistics, and pricing. The report may also provide recommendations for improving the distribution of goods and services within the feeder market.\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"<|system|>\\nYou are a helpful assistant.\\n\"\n",
    "    \"<|user|>\\nSummarize the purpose of a report that analyzes the distribution flows in feeder markets.\\n\"\n",
    "    \"<|assistant|>\\n\"\n",
    ")\n",
    "response = generator(prompt, max_new_tokens=200)[0]['generated_text']\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_FFnAj0YX46"
   },
   "source": [
    "Improving Prompt with Context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h5Cd9Bv1YYns",
    "outputId": "1fa83acf-de4f-4169-f1c8-2f0b37fec8ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are a helpful assistant that classifies business reports based on their description.\n",
      "<|user|>\n",
      "Here's an example of a report description and its purpose:\n",
      "Description: 'This report provides details about average daily rate (ADR), occupancy, and revenue trends in top-performing hotels.'\n",
      "Purpose: 'To analyze revenue performance metrics in hospitality properties.\n",
      "Now analyze this one:\n",
      "Description: 'Shows contribution of each channel to the market flow across different regions.\n",
      "Purpose:\n",
      "<|assistant|>\n",
      "This report provides insights into the contribution of each channel to the market flow across different regions. The report's purpose is to analyze the impact of different channels on the overall market performance. The report's description highlights the key findings and insights derived from the analysis.\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"<|system|>\\nYou are a helpful assistant that classifies business reports based on their description.\\n\"\n",
    "    \"<|user|>\\n\"\n",
    "    \"Here's an example of a report description and its purpose:\\n\"\n",
    "    \"Description: 'This report provides details about average daily rate (ADR), occupancy, and revenue trends in top-performing hotels.'\\n\"\n",
    "    \"Purpose: 'To analyze revenue performance metrics in hospitality properties.\\n\"\n",
    "    \"Now analyze this one:\\n\"\n",
    "    \"Description: 'Shows contribution of each channel to the market flow across different regions.\\n\"\n",
    "    \"Purpose:\"\n",
    "    \"\\n<|assistant|>\\n\"\n",
    ")\n",
    "\n",
    "response = generator(prompt, max_new_tokens=300)[0]['generated_text']\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d7-99UrYcHo"
   },
   "source": [
    "Few-Shot Prompting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DOhJJylVYdRv",
    "outputId": "acd443e3-6a37-4f17-bb4f-3a5ad206fbd5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are a helpful assistant that classifies business reports based on their description.\n",
      "<|user|>\n",
      "Below are examples of report descriptions and their business categories:\n",
      "Description: 'Tracks performance metrics for feeder markets and hotel destinations.'\n",
      "Category: 'Market Performance'\n",
      "Description: 'Analyzes average revenue per room and booking channels.'\n",
      "Category: 'Revenue Management'\n",
      "Description: 'Evaluates staffing and service efficiency across hotel departments.'\n",
      "Category: 'Operations'\n",
      "Now define the category of this one:\n",
      "Description: 'Breakdown of regional demand for group bookings.'\n",
      "Category:\n",
      "<|assistant|>\n",
      "This report is categorized under the 'Market Performance' category. It is a breakdown of regional demand for group bookings.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = (\n",
    "    \"<|system|>\\nYou are a helpful assistant that classifies business reports based on their description.\\n\"\n",
    "    \"<|user|>\\n\"\n",
    "    \"Below are examples of report descriptions and their business categories:\\n\"\n",
    "    \"Description: 'Tracks performance metrics for feeder markets and hotel destinations.'\\nCategory: 'Market Performance'\\n\"\n",
    "    \"Description: 'Analyzes average revenue per room and booking channels.'\\nCategory: 'Revenue Management'\\n\"\n",
    "    \"Description: 'Evaluates staffing and service efficiency across hotel departments.'\\nCategory: 'Operations'\\n\"\n",
    "    \"Now define the category of this one:\\n\"\n",
    "    \"Description: 'Breakdown of regional demand for group bookings.'\\nCategory:\"\n",
    "    \"\\n<|assistant|>\\n\"\n",
    ")\n",
    "response = generator(prompt, max_new_tokens=50)[0]['generated_text']\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUsXgbaZYgOC"
   },
   "source": [
    "CRISPE Prompt Template (Guided Practice):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2qWApZjYgwK",
    "outputId": "df31e7ac-2eb7-4337-e25c-4603bf3c779e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are a helpful assistant trained to classify hotel business reports based on their descriptions.\n",
      "<|user|>\n",
      "Context: You're working with a set of hotel business reports.\n",
      "Role: You are a data analyst assistant.\n",
      "Instructions: Classify the report into one of these categories: ['Market', 'Revenue', 'Operations', 'HR'].\n",
      "Steps:\n",
      "- Read the description\n",
      "- Identify the key business focus\n",
      "- Map to a category\n",
      "\n",
      "Parameters:\n",
      "- Use only one label\n",
      "- Be concise\n",
      "\n",
      "Example:\n",
      "Description: 'Shows ADR and occupancy over time per destination'\n",
      "Category: Revenue\n",
      "\n",
      "Now classify:\n",
      "Description: 'Summarizes guest complaints and staff resolution time'\n",
      "Category:\n",
      "<|assistant|>\n",
      "Based on the description, the report is categorized as Revenue. The key focus is on guest complaints and staff resolution time.\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"<|system|>\\nYou are a helpful assistant trained to classify hotel business reports based on their descriptions.\\n\"\n",
    "    \"<|user|>\\n\"\n",
    "    \"Context: You're working with a set of hotel business reports.\\n\"\n",
    "    \"Role: You are a data analyst assistant.\\n\"\n",
    "    \"Instructions: Classify the report into one of these categories: ['Market', 'Revenue', 'Operations', 'HR'].\\n\"\n",
    "    \"Steps:\\n\"\n",
    "    \"- Read the description\\n\"\n",
    "    \"- Identify the key business focus\\n\"\n",
    "    \"- Map to a category\\n\\n\"\n",
    "    \"Parameters:\\n\"\n",
    "    \"- Use only one label\\n\"\n",
    "    \"- Be concise\\n\\n\"\n",
    "    \"Example:\\n\"\n",
    "    \"Description: 'Shows ADR and occupancy over time per destination'\\n\"\n",
    "    \"Category: Revenue\\n\\n\"\n",
    "    \"Now classify:\\n\"\n",
    "    \"Description: 'Summarizes guest complaints and staff resolution time'\\n\"\n",
    "    \"Category:\"\n",
    "    \"\\n<|assistant|>\\n\"\n",
    ")\n",
    "\n",
    "response = generator(prompt, max_new_tokens=300)[0]['generated_text']\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyML0n9YhMXooK/forO1gpkW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbadenes/semantic-report-search/blob/main/data/analysis/44_RAG_from_Excel_with_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUimkfz0IWib",
        "outputId": "ebe0e2aa-040d-456a-eb21-0d458db1c09c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Collecting langchain_huggingface\n",
            "  Downloading langchain_huggingface-0.3.0-py3-none-any.whl.metadata (996 bytes)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: llama-cpp-python in /usr/local/lib/python3.11/dist-packages (0.3.9)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.32.4)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.65)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (0.21.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (4.14.0)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (5.6.3)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python) (3.1.6)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_huggingface-0.3.0-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: langchain_huggingface\n",
            "Successfully installed langchain_huggingface-0.3.0\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install dependencies\n",
        "!pip install langchain langchain_huggingface langchain_community faiss-cpu pandas openpyxl llama-cpp-python tiktoken huggingface_hub\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load the Excel spreadsheet\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel(\"Reporting_Inventory.xlsx\", sheet_name=\"Views\")\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "HcrATvAAI5nk",
        "outputId": "bca30b66-22f3-4170-a09b-601f8a7984be"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  ID Data Product           Report Name     Product Owner        PBIX_File  \\\n",
              "0       RPPBI0032  Feeder Market - 2024  Jonathan Shields  LifeReport.pbix   \n",
              "1       RPPBI0032  Feeder Market - 2024  Jonathan Shields  LifeReport.pbix   \n",
              "2       RPPBI0032  Feeder Market - 2024  Jonathan Shields  LifeReport.pbix   \n",
              "3       RPPBI0032  Feeder Market - 2024  Jonathan Shields  LifeReport.pbix   \n",
              "4       RPPBI0032  Feeder Market - 2024  Jonathan Shields  LifeReport.pbix   \n",
              "\n",
              "                     Report View  \\\n",
              "0                       CRITERIA   \n",
              "1  DESTINATION_OF_FEEDER_MARKETS   \n",
              "2                 EXECUTIVE VIEW   \n",
              "3            FEEDER MARKET FLOWS   \n",
              "4           FEEDER_MARKET_DETAIL   \n",
              "\n",
              "                                         Description     Category      Status  \\\n",
              "0  Methodolody and definition of the algorithim o...  Informative  Productive   \n",
              "1  View focused on understand the performance by ...   Functional  Productive   \n",
              "2  Global view to understand Feeder Market Perfor...    Executive  Productive   \n",
              "3  View focused on understanding the booking beha...   Functional  Productive   \n",
              "4  Detail view of Feeder Markets by Destination i...   Functional  Productive   \n",
              "\n",
              "  Rename                                         Dimensions  \\\n",
              "0    NaN                                                NaN   \n",
              "1    NaN  Hotel, month, Feeder Market, Segment, Channel ...   \n",
              "2    NaN  Hotel, month, Feeder Market, Segment, Channel ...   \n",
              "3    NaN  Hotel, month, Feeder Market, Segment, Channel ...   \n",
              "4    NaN  Hotel, month, Feeder Market, Segment, Channel ...   \n",
              "\n",
              "                                                KPIs Other Terms Filters Tags  \\\n",
              "0                                                NaN         NaN     NaN  NaN   \n",
              "1  Total Revenue, Room Revenue, RN, Lead Time, Le...         NaN     NaN  NaN   \n",
              "2  Total Revenue, Room Revenue, RN, Lead Time, Le...         NaN     NaN  NaN   \n",
              "3  Total Revenue, Room Revenue, RN, Lead Time, Le...         NaN     NaN  NaN   \n",
              "4  Total Revenue, Room Revenue, RN, Lead Time, Le...         NaN     NaN  NaN   \n",
              "\n",
              "     Priority  \n",
              "0  Priority 1  \n",
              "1  Priority 1  \n",
              "2  Priority 1  \n",
              "3  Priority 1  \n",
              "4  Priority 1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d4cc0f5-b064-48f9-8b98-d5d2e9f0b342\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID Data Product</th>\n",
              "      <th>Report Name</th>\n",
              "      <th>Product Owner</th>\n",
              "      <th>PBIX_File</th>\n",
              "      <th>Report View</th>\n",
              "      <th>Description</th>\n",
              "      <th>Category</th>\n",
              "      <th>Status</th>\n",
              "      <th>Rename</th>\n",
              "      <th>Dimensions</th>\n",
              "      <th>KPIs</th>\n",
              "      <th>Other Terms</th>\n",
              "      <th>Filters</th>\n",
              "      <th>Tags</th>\n",
              "      <th>Priority</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RPPBI0032</td>\n",
              "      <td>Feeder Market - 2024</td>\n",
              "      <td>Jonathan Shields</td>\n",
              "      <td>LifeReport.pbix</td>\n",
              "      <td>CRITERIA</td>\n",
              "      <td>Methodolody and definition of the algorithim o...</td>\n",
              "      <td>Informative</td>\n",
              "      <td>Productive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Priority 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RPPBI0032</td>\n",
              "      <td>Feeder Market - 2024</td>\n",
              "      <td>Jonathan Shields</td>\n",
              "      <td>LifeReport.pbix</td>\n",
              "      <td>DESTINATION_OF_FEEDER_MARKETS</td>\n",
              "      <td>View focused on understand the performance by ...</td>\n",
              "      <td>Functional</td>\n",
              "      <td>Productive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Hotel, month, Feeder Market, Segment, Channel ...</td>\n",
              "      <td>Total Revenue, Room Revenue, RN, Lead Time, Le...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Priority 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RPPBI0032</td>\n",
              "      <td>Feeder Market - 2024</td>\n",
              "      <td>Jonathan Shields</td>\n",
              "      <td>LifeReport.pbix</td>\n",
              "      <td>EXECUTIVE VIEW</td>\n",
              "      <td>Global view to understand Feeder Market Perfor...</td>\n",
              "      <td>Executive</td>\n",
              "      <td>Productive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Hotel, month, Feeder Market, Segment, Channel ...</td>\n",
              "      <td>Total Revenue, Room Revenue, RN, Lead Time, Le...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Priority 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RPPBI0032</td>\n",
              "      <td>Feeder Market - 2024</td>\n",
              "      <td>Jonathan Shields</td>\n",
              "      <td>LifeReport.pbix</td>\n",
              "      <td>FEEDER MARKET FLOWS</td>\n",
              "      <td>View focused on understanding the booking beha...</td>\n",
              "      <td>Functional</td>\n",
              "      <td>Productive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Hotel, month, Feeder Market, Segment, Channel ...</td>\n",
              "      <td>Total Revenue, Room Revenue, RN, Lead Time, Le...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Priority 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RPPBI0032</td>\n",
              "      <td>Feeder Market - 2024</td>\n",
              "      <td>Jonathan Shields</td>\n",
              "      <td>LifeReport.pbix</td>\n",
              "      <td>FEEDER_MARKET_DETAIL</td>\n",
              "      <td>Detail view of Feeder Markets by Destination i...</td>\n",
              "      <td>Functional</td>\n",
              "      <td>Productive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Hotel, month, Feeder Market, Segment, Channel ...</td>\n",
              "      <td>Total Revenue, Room Revenue, RN, Lead Time, Le...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Priority 1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d4cc0f5-b064-48f9-8b98-d5d2e9f0b342')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5d4cc0f5-b064-48f9-8b98-d5d2e9f0b342 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5d4cc0f5-b064-48f9-8b98-d5d2e9f0b342');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6144349a-08d3-448c-b084-4209a55874ed\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6144349a-08d3-448c-b084-4209a55874ed')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6144349a-08d3-448c-b084-4209a55874ed button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1486,\n  \"fields\": [\n    {\n      \"column\": \"ID Data Product\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 238,\n        \"samples\": [\n          \"RPPBI0208\",\n          \"RPPBI0030\",\n          \"RPPBI0183\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Report Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 206,\n        \"samples\": [\n          \"FC Automation Dashboard\",\n          \"QUESTforExcellence 2025\",\n          \"Degree Days Report\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Product Owner\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"Leslie Evans\",\n          \"Kendra Bennett\",\n          \"Elizabeth Bennett\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PBIX_File\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 224,\n        \"samples\": [\n          \"SeaReport.pbix\",\n          \"BedReport.pbix\",\n          \"EastReport.pbix\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Report View\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 758,\n        \"samples\": [\n          \"REV_DETAIL\",\n          \"Cash Open Items\",\n          \"Overall Performance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 379,\n        \"samples\": [\n          \"Shows if there is any uncategorized campaign. It has a direct access to the categorization_sheet in order to categorize new campaigns when needed.\",\n          \"This page is a summary of Campaign Manager Global  filtered by Advertiser \\u201cDisplay Performance\\u201d.\",\n          \"Page composed to show a detailed view of the declined & rejected RFP in order to see the reasons behind those RFP Status. It contains a first block of filters, an overview of the current status and the most common reasons for them, and analytics for different business cases by hotel, by account handler and by company detail\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Informative\",\n          \"Functional\",\n          \"Master Data\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Internal\",\n          \"Discontinued\",\n          \"Productive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rename\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Executive Summary\",\n          \"Commercial Approach\",\n          \"Online Ratings\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dimensions\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 97,\n        \"samples\": [\n          \"BU, Country, City, Hotel, Brand, Weekdays, Lead Time, FIT Dependency, City tax\",\n          \"Hotel Name, Hotel City, Hotel BU, Hotel Sub BU, Hotel Country, Hotel Brand, Hotel BU, Size, Segment, Feeder Market, Status, Lead Time, Currency\",\n          \"Check-Out Date, user country, page language, page referrer language, operating system, hostname, device, platform\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"KPIs\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 151,\n        \"samples\": [\n          \"Total Revenue, Number of RPF's\",\n          \"TREV, RREV, OREV, RN; COMISIONES, WEB MEDIA, RAPPEL, GDS COSTS, CONSORTIAS, FORECAST, BUDGET, EFT INFO, FORECAST BY CHANNEL\",\n          \"ADR, Value for Money Quality Score (VFM), Overall Satisfaction Quality Score (OSAT), Price Sensitivity\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Other Terms\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 51,\n        \"samples\": [\n          \"Hotel Hotels, Hotel Collection, Tivoli, Anantara, Avani, NHOW, Other Brands, Venue\",\n          \"Scope 1 emissions, Scope 2 emissions\",\n          \"Actuals, Predicted;Forecast, TY, LY, LY2, NY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Filters\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"Comparable_Rate is YES, Hotel_Status is OPEN\",\n          \"Hotel_ID is not (blank)\",\n          \"Anantara Hotels\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tags\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 78,\n        \"samples\": [\n          \"Quality, Risk, Booking\",\n          \"B2B Digital\",\n          \"Quality, Risk, Google\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Priority\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Priority 1\",\n          \"Priority 2\",\n          \"Priority 4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Convert rows to LangChain Documents\n",
        "from langchain.schema import Document\n",
        "\n",
        "def row_to_document(row):\n",
        "    content = \"\\n\".join([f\"{col}: {row[col]}\" for col in row.index if pd.notnull(row[col])])\n",
        "    return Document(page_content=content)\n",
        "\n",
        "documents = [row_to_document(row) for _, row in df.iterrows()]\n",
        "print(f\"{len(documents)} documents created.\")\n",
        "print(\"Document:\\n\", documents[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tcv6DOLKI7wW",
        "outputId": "3174b940-ef34-45d1-f84d-50f206b7aabe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1486 documents created.\n",
            "Document:\n",
            " page_content='ID Data Product: RPPBI0032\n",
            "Report Name: Feeder Market - 2024\n",
            "Product Owner: Jonathan Shields\n",
            "PBIX_File: LifeReport.pbix\n",
            "Report View: CRITERIA\n",
            "Description: Methodolody and definition of the algorithim of Feeder Market\n",
            "Category: Informative\n",
            "Status: Productive\n",
            "Priority: Priority 1'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from huggingface_hub import login\n",
        "# login(token=\"hf_xxx...\")\n",
        "\n",
        "# Step 4: Embed documents using a local embedding model (default: huggingface-based)\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# You can change the model to another one like 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "vectorstore = FAISS.from_documents(documents, embedding_model)\n"
      ],
      "metadata": {
        "id": "1e9SehyxJJF3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the GGUF model from Hugging Face:\n",
        "# https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "model_path = hf_hub_download(\n",
        "    repo_id=\"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\n",
        "    #filename=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\",\n",
        "    filename=\"mistral-7b-instruct-v0.1.Q2_K.gguf\"\n",
        "    local_dir=\"/content\"  # o cualquier otra ruta\n",
        ")\n",
        "\n",
        "print(\"Model downloaded in:\", model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "fQD162-aKa4U",
        "outputId": "b75357e5-f5fa-4df6-e74e-a1b8823f4e54"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Perhaps you forgot a comma? (<ipython-input-24-1627421904>, line 9)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-1627421904>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    filename=\"mistral-7b-instruct-v0.1.Q2_K.gguf\"\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Load a local LLM using llama-cpp\n",
        "from langchain.llms import LlamaCpp\n",
        "\n",
        "# Make sure you have a GGUF model (like mistral-7b-instruct-v0.1.Q4_K_M.gguf)\n",
        "MODEL_PATH = \"/content/mistral-7b-instruct-v0.1.Q4_K_M.gguf\"  # Change to your model's path\n",
        "\n",
        "llm = LlamaCpp(\n",
        "    model_path=MODEL_PATH,\n",
        "    temperature=0.7,  # Controls the randomness of the model's output. Lower values make responses more deterministic.\n",
        "    max_tokens=512,   # The maximum number of tokens the model is allowed to generate in its response.\n",
        "    top_p=0.95,       # Limits the sampling to the smallest possible set of tokens whose cumulative probability is ≥ top_p.\n",
        "    n_ctx=2048,       # Maximum number of context tokens (prompt + output) that the model can handle. This should not exceed the context length of your model (e.g. 2048, 4096, 8192).\n",
        "    verbose=True      # If True, prints debug-level logs during inference (token generation steps, etc.).\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z21FCix-JPaf",
        "outputId": "34c660bc-9381-43f6-8c34-beb818a35120"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from /content/mistral-7b-instruct-v0.1.Q4_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.1\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "print_info: file format = GGUF V2\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 4.07 GiB (4.83 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 1\n",
            "load: control token:      2 '</s>' is not marked as EOG\n",
            "load: control token:      1 '<s>' is not marked as EOG\n",
            "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "load: special tokens cache size = 3\n",
            "load: token to piece cache size = 0.1637 MB\n",
            "print_info: arch             = llama\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 32768\n",
            "print_info: n_embd           = 4096\n",
            "print_info: n_layer          = 32\n",
            "print_info: n_head           = 32\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 128\n",
            "print_info: n_swa            = 0\n",
            "print_info: n_swa_pattern    = 1\n",
            "print_info: n_embd_head_k    = 128\n",
            "print_info: n_embd_head_v    = 128\n",
            "print_info: n_gqa            = 4\n",
            "print_info: n_embd_k_gqa     = 1024\n",
            "print_info: n_embd_v_gqa     = 1024\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 14336\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 0\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 10000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 32768\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: ssm_d_conv       = 0\n",
            "print_info: ssm_d_inner      = 0\n",
            "print_info: ssm_d_state      = 0\n",
            "print_info: ssm_dt_rank      = 0\n",
            "print_info: ssm_dt_b_c_rms   = 0\n",
            "print_info: model type       = 7B\n",
            "print_info: model params     = 7.24 B\n",
            "print_info: general.name     = mistralai_mistral-7b-instruct-v0.1\n",
            "print_info: vocab type       = SPM\n",
            "print_info: n_vocab          = 32000\n",
            "print_info: n_merges         = 0\n",
            "print_info: BOS token        = 1 '<s>'\n",
            "print_info: EOS token        = 2 '</s>'\n",
            "print_info: UNK token        = 0 '<unk>'\n",
            "print_info: LF token         = 13 '<0x0A>'\n",
            "print_info: EOG token        = 2 '</s>'\n",
            "print_info: max token length = 48\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   1 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   2 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   3 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   4 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   6 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   7 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   8 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer   9 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  10 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  12 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  13 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  14 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  15 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  16 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  18 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  19 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  20 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  21 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  22 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  24 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  25 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  26 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  27 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  28 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  29 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  30 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  31 assigned to device CPU, is_swa = 0\n",
            "load_tensors: layer  32 assigned to device CPU, is_swa = 0\n",
            "load_tensors: tensor 'token_embd.weight' (q4_K) (and 98 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
            "load_tensors:  CPU_AARCH64 model buffer size =  3204.00 MiB\n",
            "load_tensors:   CPU_Mapped model buffer size =  4165.37 MiB\n",
            "repack: repack tensor blk.0.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.0.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.0.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.1.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.1.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.1.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.2.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.2.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.2.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.3.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.3.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.3.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.4.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.4.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.4.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.4.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.5.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.5.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.5.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.6.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.6.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.6.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.7.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.7.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.7.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.7.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.8.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.8.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.9.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.9.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.9.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.10.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.10.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.10.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.10.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.11.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.11.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.11.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.11.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.12.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.12.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.12.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.13.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.13.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.13.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.14.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.14.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.14.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.14.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.15.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.15.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.15.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.16.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.16.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.16.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.16.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.17.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.17.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.17.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.17.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.18.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.18.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.18.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.19.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.19.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.19.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.19.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.20.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.20.ffn_down.weight with q4_K_8x8\n",
            "repack: repack tensor blk.20.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.21.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.21.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.21.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.21.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.21.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.22.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.attn_v.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.22.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.22.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.22.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.23.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.attn_output.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.23.ffn_gate.weight with q4_K_8x8\n",
            "repack: repack tensor blk.23.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.23.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.24.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.24.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.24.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.25.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.25.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.25.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.25.ffn_up.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.26.attn_q.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.attn_v.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.26.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.26.ffn_down.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.26.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.27.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.27.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.27.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.27.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.27.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.28.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.28.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.28.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.28.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.28.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.29.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.29.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.29.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.29.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.29.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.30.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.30.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.30.ffn_up.weight with q4_K_8x8\n",
            "repack: repack tensor blk.31.attn_q.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.31.attn_k.weight with q4_K_8x8\n",
            "repack: repack tensor blk.31.attn_output.weight with q4_K_8x8\n",
            "repack: repack tensor blk.31.ffn_gate.weight with q4_K_8x8\n",
            ".repack: repack tensor blk.31.ffn_up.weight with q4_K_8x8\n",
            "...................\n",
            "llama_context: constructing llama_context\n",
            "llama_context: n_batch is less than GGML_KQ_MASK_PAD - increasing to 64\n",
            "llama_context: n_seq_max     = 1\n",
            "llama_context: n_ctx         = 2048\n",
            "llama_context: n_ctx_per_seq = 2048\n",
            "llama_context: n_batch       = 64\n",
            "llama_context: n_ubatch      = 8\n",
            "llama_context: causal_attn   = 1\n",
            "llama_context: flash_attn    = 0\n",
            "llama_context: freq_base     = 10000.0\n",
            "llama_context: freq_scale    = 1\n",
            "llama_context: n_ctx_per_seq (2048) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
            "set_abort_callback: call\n",
            "llama_context:        CPU  output buffer size =     0.12 MiB\n",
            "create_memory: n_ctx = 2048 (padded)\n",
            "llama_kv_cache_unified: kv_size = 2048, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1, padding = 32\n",
            "llama_kv_cache_unified: layer   0: dev = CPU\n",
            "llama_kv_cache_unified: layer   1: dev = CPU\n",
            "llama_kv_cache_unified: layer   2: dev = CPU\n",
            "llama_kv_cache_unified: layer   3: dev = CPU\n",
            "llama_kv_cache_unified: layer   4: dev = CPU\n",
            "llama_kv_cache_unified: layer   5: dev = CPU\n",
            "llama_kv_cache_unified: layer   6: dev = CPU\n",
            "llama_kv_cache_unified: layer   7: dev = CPU\n",
            "llama_kv_cache_unified: layer   8: dev = CPU\n",
            "llama_kv_cache_unified: layer   9: dev = CPU\n",
            "llama_kv_cache_unified: layer  10: dev = CPU\n",
            "llama_kv_cache_unified: layer  11: dev = CPU\n",
            "llama_kv_cache_unified: layer  12: dev = CPU\n",
            "llama_kv_cache_unified: layer  13: dev = CPU\n",
            "llama_kv_cache_unified: layer  14: dev = CPU\n",
            "llama_kv_cache_unified: layer  15: dev = CPU\n",
            "llama_kv_cache_unified: layer  16: dev = CPU\n",
            "llama_kv_cache_unified: layer  17: dev = CPU\n",
            "llama_kv_cache_unified: layer  18: dev = CPU\n",
            "llama_kv_cache_unified: layer  19: dev = CPU\n",
            "llama_kv_cache_unified: layer  20: dev = CPU\n",
            "llama_kv_cache_unified: layer  21: dev = CPU\n",
            "llama_kv_cache_unified: layer  22: dev = CPU\n",
            "llama_kv_cache_unified: layer  23: dev = CPU\n",
            "llama_kv_cache_unified: layer  24: dev = CPU\n",
            "llama_kv_cache_unified: layer  25: dev = CPU\n",
            "llama_kv_cache_unified: layer  26: dev = CPU\n",
            "llama_kv_cache_unified: layer  27: dev = CPU\n",
            "llama_kv_cache_unified: layer  28: dev = CPU\n",
            "llama_kv_cache_unified: layer  29: dev = CPU\n",
            "llama_kv_cache_unified: layer  30: dev = CPU\n",
            "llama_kv_cache_unified: layer  31: dev = CPU\n",
            "llama_kv_cache_unified:        CPU KV buffer size =   256.00 MiB\n",
            "llama_kv_cache_unified: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_context: enumerating backends\n",
            "llama_context: backend_ptrs.size() = 1\n",
            "llama_context: max_nodes = 65536\n",
            "llama_context: worst-case: n_tokens = 8, n_seqs = 1, n_outputs = 0\n",
            "llama_context: reserving graph for n_tokens = 8, n_seqs = 1\n",
            "llama_context: reserving graph for n_tokens = 1, n_seqs = 1\n",
            "llama_context: reserving graph for n_tokens = 8, n_seqs = 1\n",
            "llama_context:        CPU compute buffer size =     3.00 MiB\n",
            "llama_context: graph nodes  = 1094\n",
            "llama_context: graph splits = 1\n",
            "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-instruct-v0.1', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Using fallback chat format: llama-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Build the RetrievalQA chain\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n"
      ],
      "metadata": {
        "id": "GkuWytiAJV2K"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Ask your question\n",
        "query = \"Which reports are related to financial resources?\"\n",
        "response = qa_chain.invoke({\"query\": query})\n",
        "\n",
        "print(\"Answer:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbmpD74JJYjI",
        "outputId": "e4352700-28a4-4adf-d2e4-d9ba35761b6f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =  325599.24 ms\n",
            "llama_perf_context_print: prompt eval time =  325599.04 ms /   908 tokens (  358.59 ms per token,     2.79 tokens per second)\n",
            "llama_perf_context_print:        eval time =   21402.47 ms /    32 runs   (  668.83 ms per token,     1.50 tokens per second)\n",
            "llama_perf_context_print:       total time =  347035.24 ms /   940 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:\n",
            "{'query': 'Which reports are related to financial resources?', 'result': ' The reports \"Budget 2025 Report\" and \"Daily Revenue Report 2025\" are related to financial resources.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Ask your question\n",
        "query = \"What views provide KPIs for service performance?\"\n",
        "response = qa_chain.invoke({\"query\": query})\n",
        "\n",
        "print(\"Answer:\", response)\n"
      ],
      "metadata": {
        "id": "dArs1rMQOzH8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
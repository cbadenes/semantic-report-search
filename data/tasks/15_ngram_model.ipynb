{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99af4aef",
   "metadata": {},
   "source": [
    "# N-Gram Model from Report Descriptions\n",
    "\n",
    "This notebook create a **n-gram model** from the `Description` column using `nltk`, in order to expand the `keywords` used in search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04854cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/cbadenes/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cbadenes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Install required NLTK resources (if running for the first time)\n",
    "# !pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from nltk import FreqDist\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"openpyxl\")\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1d9045",
   "metadata": {},
   "source": [
    "## Load and prepare report descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aefb0e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Methodolody and definition of the algorithim of Feeder Market',\n",
       " 'View focused on understand the performance by hotel for a specific feeder market o selection of feeder marktes. ',\n",
       " 'Global view to understand Feeder Market Performance compared to previous years diferentiating between domestic and international',\n",
       " 'View focused on understanding the booking behaviour by Feeder Market. It allows to understand when, where and through which channels and segments are producing the different feeder markets for a selected booking period. Besides, it shows the flow (Feeder Market to Destination) by contribution of total revenue',\n",
       " 'Detail view of Feeder Markets by Destination including more indepth view by channel, and including Top_Agency and Top_Company information',\n",
       " 'VIew focused on understanding the feeder markets producing at a specific Destination',\n",
       " 'Index page with interactive buttons to other views.',\n",
       " 'Benchmark by Destination. Outside information is provided by Oxford Economics providing a summary developed by AI',\n",
       " 'View that provides performance vs budget at a feeder Market level. It allows to drill down by destination, segment and channel',\n",
       " 'Methodolody and definition of the algorithim of Feeder Market']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Views sheet\n",
    "views_path = Path(\"../raw/Reporting_Inventory.xlsx\")\n",
    "views_df = pd.read_excel(views_path, sheet_name=\"Views\")\n",
    "views_df.fillna(\"\", inplace=True)\n",
    "views_df = views_df[views_df[\"Description\"].str.strip() != \"\"]\n",
    "descriptions = views_df[\"Description\"].dropna().astype(str).tolist()\n",
    "descriptions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc22334b",
   "metadata": {},
   "source": [
    "### Preprocess text: lowercase, clean, remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07b08850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['methodolody', 'definition', 'algorithim', 'feeder', 'market'],\n",
       " ['view',\n",
       "  'focused',\n",
       "  'understand',\n",
       "  'performance',\n",
       "  'hotel',\n",
       "  'specific',\n",
       "  'feeder',\n",
       "  'market',\n",
       "  'selection',\n",
       "  'feeder',\n",
       "  'marktes'],\n",
       " ['global',\n",
       "  'view',\n",
       "  'understand',\n",
       "  'feeder',\n",
       "  'market',\n",
       "  'performance',\n",
       "  'compared',\n",
       "  'previous',\n",
       "  'years',\n",
       "  'diferentiating',\n",
       "  'domestic',\n",
       "  'international'],\n",
       " ['view',\n",
       "  'focused',\n",
       "  'understanding',\n",
       "  'booking',\n",
       "  'behaviour',\n",
       "  'feeder',\n",
       "  'market',\n",
       "  'allows',\n",
       "  'understand',\n",
       "  'channels',\n",
       "  'segments',\n",
       "  'producing',\n",
       "  'different',\n",
       "  'feeder',\n",
       "  'markets',\n",
       "  'selected',\n",
       "  'booking',\n",
       "  'period',\n",
       "  'besides',\n",
       "  'shows',\n",
       "  'flow',\n",
       "  'feeder',\n",
       "  'market',\n",
       "  'destination',\n",
       "  'contribution',\n",
       "  'total',\n",
       "  'revenue'],\n",
       " ['detail',\n",
       "  'view',\n",
       "  'feeder',\n",
       "  'markets',\n",
       "  'destination',\n",
       "  'including',\n",
       "  'indepth',\n",
       "  'view',\n",
       "  'channel',\n",
       "  'including',\n",
       "  'topagency',\n",
       "  'topcompany',\n",
       "  'information'],\n",
       " ['view',\n",
       "  'focused',\n",
       "  'understanding',\n",
       "  'feeder',\n",
       "  'markets',\n",
       "  'producing',\n",
       "  'specific',\n",
       "  'destination'],\n",
       " ['index', 'page', 'interactive', 'buttons', 'views'],\n",
       " ['benchmark',\n",
       "  'destination',\n",
       "  'outside',\n",
       "  'information',\n",
       "  'provided',\n",
       "  'oxford',\n",
       "  'economics',\n",
       "  'providing',\n",
       "  'summary',\n",
       "  'developed',\n",
       "  'ai'],\n",
       " ['view',\n",
       "  'provides',\n",
       "  'performance',\n",
       "  'vs',\n",
       "  'budget',\n",
       "  'feeder',\n",
       "  'market',\n",
       "  'level',\n",
       "  'allows',\n",
       "  'drill',\n",
       "  'destination',\n",
       "  'segment',\n",
       "  'channel'],\n",
       " ['methodolody', 'definition', 'algorithim', 'feeder', 'market']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define English stopwords (can switch to 'spanish' if needed)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    Normalize, tokenize, and clean a single string of text.\n",
    "    \"\"\"\n",
    "    # Lowercase and remove punctuation\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-záéíóúñü\\s]\", \"\", text)\n",
    "    \n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [t for t in tokens if t not in stop_words]\n",
    "    \n",
    "    return filtered_tokens\n",
    "\n",
    "# Apply preprocessing to each report description\n",
    "token_lists = [preprocess(desc) for desc in descriptions]\n",
    "token_lists[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516864bd",
   "metadata": {},
   "source": [
    "### Generate and analyze bigrams and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a91fda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 bigrams:\n",
      "[(('index', 'page'), 51), (('buttons', 'views'), 50), (('page', 'interactive'), 48), (('interactive', 'buttons'), 48), (('feeder', 'market'), 44), (('first', 'block'), 39), (('detail', 'regarding'), 37), (('block', 'filters'), 35), (('view', 'analyze'), 34), (('dynamic', 'table'), 31)]\n",
      "\n",
      "Top 10 trigrams:\n",
      "[(('index', 'page', 'interactive'), 48), (('page', 'interactive', 'buttons'), 48), (('interactive', 'buttons', 'views'), 48), (('first', 'block', 'filters'), 35), (('contains', 'first', 'block'), 21), (('month', 'week', 'evolution'), 19), (('quest', 'detail', 'regarding'), 17), (('view', 'shows', 'first'), 15), (('shows', 'first', 'block'), 15), (('block', 'filters', 'second'), 15)]\n"
     ]
    }
   ],
   "source": [
    "# Flatten all tokens into a single list\n",
    "all_tokens = [token for tokens in token_lists for token in tokens]\n",
    "\n",
    "# Build bigrams and trigrams\n",
    "bigrams = list(ngrams(all_tokens, 2))\n",
    "trigrams = list(ngrams(all_tokens, 3))\n",
    "\n",
    "# Compute frequency distributions\n",
    "bigram_freq = FreqDist(bigrams)\n",
    "trigram_freq = FreqDist(trigrams)\n",
    "\n",
    "# Preview top 10 n-grams\n",
    "print(\"Top 10 bigrams:\")\n",
    "print(bigram_freq.most_common(10))\n",
    "\n",
    "print(\"\\nTop 10 trigrams:\")\n",
    "print(trigram_freq.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a2f0347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Build bigram prediction index: word -> list of possible next words sorted by frequency\n",
    "bigram_index = defaultdict(list)\n",
    "for (w1, w2), freq in bigram_freq.items():\n",
    "    bigram_index[w1].append((w2, freq))\n",
    "\n",
    "# Sort each list of next-word suggestions by frequency\n",
    "for w1 in bigram_index:\n",
    "    bigram_index[w1] = sorted(bigram_index[w1], key=lambda x: -x[1])\n",
    "\n",
    "# Convertir a dict serializable\n",
    "serializable_index = {k: v for k, v in bigram_index.items()}\n",
    "\n",
    "# Save dictionary as JSON\n",
    "with open(\"../models/bigram_index.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(serializable_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81f03ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggestions for 'feeder': ['market']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def suggest_next_word(word, top_n=1):\n",
    "    \"\"\"\n",
    "    Given a word, suggest the most likely next tokens based on bigram frequencies.\n",
    "    \"\"\"\n",
    "    word = word.lower()\n",
    "    if word in bigram_index:\n",
    "        return [next_word for next_word, _ in bigram_index[word][:top_n]]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Example usage:\n",
    "ref_word = \"feeder\"\n",
    "print(\"Suggestions for '\"+ref_word+\"':\", suggest_next_word(ref_word, top_n=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee858bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
